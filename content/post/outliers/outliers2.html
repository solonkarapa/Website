---
title: "Outliers: Which prior are you using?"
subtitle: "The problem of outliers from a Bayesian viewpoint"
author: ''
date: '2021-05-22'
slug: outliers
categories: [Bayes]
tags: [Bayes]
output: 
  bookdown::html_document2: 
    fig_caption: yes
header:
  caption: ''
  image: ''
bibliography: sample.bib
link-citations: yes
draft: TRUE
---



<p>This post is concerned with a ubiquitous problem in many fields – outliers. They degrade the performance of many models/algorithms. As a result, there are ongoing attempts to accommodate outlying observations by deriving robust estimators. But these estimators have drawbacks such as being less efficient. Here, I illustrate how the problem of outliers connects with our prior beliefs about the data collection procedure. This leads me to show how a simple but flexible Bayesian model allows to accommodate outliers without inheriting the drawback of other estimators.</p>
<p>Disclaimer: This post is heavily inspired by the work of <span class="citation">Jaynes (<a href="#ref-jaynes2003probability" role="doc-biblioref">2003</a>)</span>.</p>
<div id="the-problem" class="section level2">
<h2>The problem</h2>
<p>Imagine we are interested in a quantity <span class="math inline">\(\theta\)</span>, which is unknown. The subsequent, logical step is to try to quantify our uncertainty about <span class="math inline">\(\theta\)</span> by collecting some data. That is, we are trying to measure <span class="math inline">\(\theta\)</span>. But the apparatus or the data collection procedure is always imperfect and so having <span class="math inline">\(n\)</span> independent measurements of <span class="math inline">\(\theta\)</span>, we have <span class="math inline">\(n\)</span> different results ($x_1, , x_n $). How are we going to proceed on estimating <span class="math inline">\(\theta\)</span>, what is the “best” estimate to use?
If the <span class="math inline">\(n\)</span> data points are “close” together the problem of drawing conclusion about <span class="math inline">\(\theta\)</span> is not very difficult. But if they are not nicely clustered: one value, <span class="math inline">\(x_j\)</span>, lies far away from the other <span class="math inline">\(n-1\)</span> values? How are we going to deal with this outlier<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>?</p>
</div>
<div id="the-dilemma" class="section level2">
<h2>The dilemma</h2>
<p>Two opposite views have been expressed on how to deal with the outlier:</p>
<ol style="list-style-type: decimal">
<li>It should not have been included in the data. The data have been contaminated and the outlier needs to be removed otherwise we may get erroneous conclusions.</li>
<li>The outlier may be the most important datapoint we have so it must be taken into account in the analysis. In other words, it may be desirable to describe the population including all observations. For only in that way do we describe what is actually happening <span class="citation">(Dixon <a href="#ref-dixon1950analysis" role="doc-biblioref">1950</a>)</span>.</li>
</ol>
<p>These viewpoints reflect different prior information about the data collection procedure. The first view is reasonable if we believe <em>a priori</em> the data collection procedure is unreliable. That is, any now and then and without warning we can get an erroneous measurement. The second view is reasonable if we have absolute confidence in the data collection procedure. Then the outlier is an important result and ignoring it may harm us.</p>
<p>Clearly these are extreme positions, and in real-life the researcher/data collector is in a intermediate position. If they knew the apparatus is unreliable they have choose not to collect data in the first place or improve the apparatus. Of course, in some situations we are obliged to use whatever “apparatus” we have access to. So the question arises can we formalise an intermediate position?</p>
</div>
<div id="robustness" class="section level2">
<h2>Robustness</h2>
<p>Such an intermediate position is the idea of robustness. Researchers sometimes use various “robust” procedures, which protect against the possibility (or presence) of outliers. These techniques do not directly examine the outliers but accommodate them at no serious inconvenience <span class="citation">(Barnett and Lewis <a href="#ref-barnett1974outliers" role="doc-biblioref">1974</a>)</span>. Certain estimators, especially the mean and least squares estimators, are particularly vulnerable to outliers, or have low breakdown values<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>For this reason, researchers turn to robust or high breakdown methods to provide alternative estimators for these important aspects of the data. A common robust estimation method for univariate distributions involves the use of a trimmed mean, which is calculated by temporarily eliminating extreme observations at both ends of the sample (very high and low values) <span class="citation">(Anscombe <a href="#ref-anscombe1960rejection" role="doc-biblioref">1960</a>)</span>. Alternatively, researchers may choose to compute a Windsorized mean, for which the highest and lowest observations are temporarily censored, and replaced with adjacent values from the remaining data.</p>
<p>The issue arises from the fact that robust qualities - however defined - must
be bought at a price: the price of poorer performance when the model is correct. This is usually reported by some trade-off between the conflicting requirements of robustness and accuracy.</p>
<p>As an example, lets look at the median which is often cited as a robust estimator. The downside of the median is that it is less efficient than the mean. This is because it does not take into account the precise value of each observation and hence does not use all information available in the data. The standard error of the median (<span class="math inline">\(\sigma_{median}\)</span>) for large samples and normal distributions is:</p>
<p><span class="math display">\[ \sigma_{median} \approx 1.25 \frac{\sigma}{\sqrt{N}} = 1.25 \sigma_{mean}\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is the population standard deviation and <span class="math inline">\(N\)</span> the sample size.
Thus, the standard error of the median is about <span class="math inline">\(25\%\)</span> larger than that for the mean <span class="citation">(Maindonald and Braun <a href="#ref-maindonald2006data" role="doc-biblioref">2006</a>, Chapter 4)</span>. Hence, the median is less efficient estimator when the model in correct, i.e the data come from a normal distributions. Later, we show that Bayesian analysis automatically delivers robustness whenever it is desirable without throwing away relevant information. But first we introduce how the apparatus generates data.</p>
</div>
<div id="the-model" class="section level2">
<h2>The model</h2>
<p>Following <span class="citation">Box and Tiao (<a href="#ref-box1968bayesian" role="doc-biblioref">1968</a>)</span> we assume that the apparatus produces good and bad measurements. So we have a  sampling distribution</p>
<p><span class="math display">\[G(x|\theta)\]</span></p>
<p>parametrized by <span class="math inline">\(\theta\)</span>. The  sampling distribution</p>
<p><span class="math display">\[B(x|\xi)\]</span></p>
<p>possibly containing an uninteresting parameter <span class="math inline">\(\xi\)</span>. Data from <span class="math inline">\(B(x|\xi)\)</span> are useless or worse for estimating <span class="math inline">\(\theta\)</span>, since their occurrence probability has nothing to do with <span class="math inline">\(\theta\)</span>. Our sample consists of <span class="math inline">\(n\)</span> observations</p>
<p><span class="math display">\[D = (x_1 \dots x_n).\]</span>
The trouble is we do not know which is which. However, we may be able to guess since a datapoint far away from the tails of <span class="math inline">\(G(x|\theta)\)</span> can be suspected of being bad. Let’s define</p>
<p><span class="math display">\[\begin{equation}
       q_i = 
        \begin{cases}
            1 &amp; \text{if the ith datapoint is good} \\
            0 &amp; \text{if it is bad,}
        \end{cases} 
\end{equation}\]</span></p>
<p>with joint prior probabilities</p>
<p><span class="math display">\[p(q_1 \dots q_n)\]</span></p>
<p>to the <span class="math inline">\(2^n\)</span> sequences of good and bad.</p>
<p>Consider the most common case where our prior information about the good and bad observations is invariant on the particular trial at which they occur. That is, the probability of any sequence of <span class="math inline">\(n\)</span> good/bad observations depends only on the numbers <span class="math inline">\(r\)</span>, <span class="math inline">\(n-r\)</span> of good and bad ones. Then, under de Finetti’s representation theorem <span class="citation">(De Finetti <a href="#ref-de1972probability" role="doc-biblioref">1972</a>)</span></p>
<p><span class="math display">\[\begin{equation}
p(q_1 \dots q_n) = \int_{0}^{1} u^r (1-u)^{n-r} dg(u).
(\#eq:de_finetti)
\end{equation}\]</span></p>
<p>The theorem above is equivalent to assuming that <span class="math inline">\(q_i\)</span> are independent Bern(<span class="math inline">\(u\)</span>) (Bernoulli) random variables with <span class="math inline">\(u\)</span>, given a prior distribution <span class="math inline">\(g(u)\)</span>. Consequently, our sampling distribution can be written as a probability mixture of the good and bad distributions</p>
<p><span class="math display" id="eq:mixturedistr">\[\begin{equation}
p(x|\theta,\xi,u) = u G(x|\theta) + (1-u) B(x|\xi). 
\tag{1}
\end{equation}\]</span></p>
<p><span class="math inline">\(\theta\)</span> can be thought of the parameter of interest while (<span class="math inline">\(\xi,u\)</span>) are nuisance parameters.
In the next section, I show how a simple, flexible Bayesian solution allows for robustness. Throughout I assume <span class="math inline">\(u\)</span> is unknown, which is in line to real-life scenarios.</p>
<div id="the-solution" class="section level3">
<h3>The solution</h3>
<p>Let <span class="math inline">\(p(\theta,\xi,u)\)</span> be the joint prior density for the parameters. Under Bayes theorem their joint posterior density, given the data <span class="math inline">\(D\)</span>, becomes</p>
<p><span class="math display">\[p(\theta,\xi,u|D) \propto L(\theta,\xi,u) p(\theta,\xi,u),\]</span></p>
<p>and from <a href="#eq:mixturedistr">(1)</a>,</p>
<p><span class="math display">\[\begin{equation}
L(\theta,\xi,u) = \prod_{i=1}^{n} \Big[ u G(x|\theta) + (1-u) B(x|\xi) \Big]
\label{jointlikelihood}
\end{equation}\]</span></p>
<p>is the likelihood. The marginal posterior density for the parameter of interest <span class="math inline">\(\theta\)</span> is</p>
<p><span class="math display" id="eq:marginaltheta">\[\begin{equation}
p(\theta|D) = \int \int p(\theta,\xi,u|D) d\xi du.
\tag{2}
\end{equation}\]</span></p>
<p>Another formulation of <a href="#eq:marginaltheta">(2)</a> is</p>
<p><span class="math display">\[ p(\theta|D) = \frac{p(\theta) \bar{L}(\theta)} {\int p(\theta) \bar{L}(\theta) d\theta}\]</span></p>
<p>where <span class="math inline">\(p(\theta)\)</span> is the marginal prior density for <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\bar{L}(\theta)\)</span> is the quasi-likelihood defined as</p>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-anscombe1960rejection">
<p>Anscombe, Frank J. 1960. “Rejection of Outliers.” <em>Technometrics</em> 2 (2): 123–46.</p>
</div>
<div id="ref-barnett1974outliers">
<p>Barnett, Vic, and Toby Lewis. 1974. <em>Outliers in Statistical Data</em>. Wiley.</p>
</div>
<div id="ref-box1968bayesian">
<p>Box, George EP, and George C Tiao. 1968. “A Bayesian Approach to Some Outlier Problems.” <em>Biometrika</em> 55 (1): 119–29.</p>
</div>
<div id="ref-de1972probability">
<p>De Finetti, Bruno. 1972. “Probability, Induction, and Statistics.”</p>
</div>
<div id="ref-dixon1950analysis">
<p>Dixon, Wilfred J. 1950. “Analysis of Extreme Values.” <em>The Annals of Mathematical Statistics</em> 21 (4): 488–506.</p>
</div>
<div id="ref-grubbs1969procedures">
<p>Grubbs, Frank E. 1969. “Procedures for Detecting Outlying Observations in Samples.” <em>Technometrics</em> 11 (1): 1–21.</p>
</div>
<div id="ref-jaynes2003probability">
<p>Jaynes, Edwin T. 2003. <em>Probability Theory: The Logic of Science</em>. Cambridge university press.</p>
</div>
<div id="ref-maindonald2006data">
<p>Maindonald, John, and John Braun. 2006. <em>Data Analysis and Graphics Using R: An Example-Based Approach</em>. Vol. 10. Cambridge University Press.</p>
</div>
<div id="ref-serfling2011asymptotic">
<p>Serfling, Robert. 2011. “Asymptotic Relative Efficiency in Estimation.” <em>International Encyclopedia of Statistical Science</em> 23 (13): 68–72.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I define an outlier as an observation which seems “to deviate markedly from the other members of the data sample in which it appears.” <span class="citation">(Grubbs <a href="#ref-grubbs1969procedures" role="doc-biblioref">1969</a>)</span>?<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The breakdown point of an estimator is the proportion of incorrect observations (e.g. arbitrarily large observations) an estimator can handle before giving an incorrect (e.g., arbitrarily large) result. See <span class="citation">Serfling (<a href="#ref-serfling2011asymptotic" role="doc-biblioref">2011</a>)</span> for a formal definition.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
