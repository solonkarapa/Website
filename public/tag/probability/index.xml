<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>probability | </title>
    <link>https://solon-karapanagiotis.com/tag/probability/</link>
      <atom:link href="https://solon-karapanagiotis.com/tag/probability/index.xml" rel="self" type="application/rss+xml" />
    <description>probability</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Solon Karapanagiotis 2018-2021</copyright><lastBuildDate>Tue, 05 Feb 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://solon-karapanagiotis.com/media/icon.png</url>
      <title>probability</title>
      <link>https://solon-karapanagiotis.com/tag/probability/</link>
    </image>
    
    <item>
      <title>Approximating Binomial with Poisson</title>
      <link>https://solon-karapanagiotis.com/post/approx_binomial/approximating-binomial-with-poisson/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://solon-karapanagiotis.com/post/approx_binomial/approximating-binomial-with-poisson/</guid>
      <description>


&lt;p&gt;It is usually taught in statistics classes that Binomial probabilities can be approximated by Poisson probabilities, which are generally easier to calculate. This approximation is valid “when &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is large and &lt;span class=&#34;math inline&#34;&gt;\(np\)&lt;/span&gt; is small,” and rules of thumb are sometimes given.&lt;/p&gt;
&lt;p&gt;In this post I’ll walk through a simple proof showing that the Poisson distribution is really just the Binomial with &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; (the number of trials) approaching infinity and &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; (the probability of success in each trail) approaching zero. I’ll then provide some numerical examples to investigate how good is the approximation.&lt;/p&gt;
&lt;div id=&#34;proof&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Proof&lt;/h2&gt;
&lt;p&gt;The Binomial distribution describes the probability that there will be &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; successes in a sample
of size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, chosen with replacement from a population where the probability of success is &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(X \sim Binomial(n, p)\)&lt;/span&gt;, that is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:binom&#34;&gt;\[\begin{equation}
\tag{1}
   P(X = x) = {n\choose x} p^x (1-p)^{n-x},
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(x= 0, 1, \dots, n\)&lt;/span&gt;. Define the number&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\lambda = np\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the rate of success. That’s the number of trials &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;—however many there are—times the chance of success &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; for each of those trials. If we repeat the experiment every day, we will be getting &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; successes per day on average.&lt;/p&gt;
&lt;p&gt;Solving for &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;, we get:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ p = \frac{\lambda}{n}\]&lt;/span&gt;
We then substitute this into &lt;a href=&#34;#eq:binom&#34;&gt;(1)&lt;/a&gt;, and take the limit as &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; goes to infinity&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \lim_{n \to \infty}P(X = x) =  \lim_{n \to \infty} \frac{n!}{x!(n-x)!} \bigg( \frac{\lambda}{n} \bigg)^x \bigg( 1-\frac{\lambda}{n} \bigg)^{n-x}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I then collect the constants (terms that don’t depend on &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;) in front and split the last term into two&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:limit&#34;&gt;\[\begin{equation}
   \tag{2}
   \frac{\lambda^x}{x!}  \lim_{n \to \infty} \color{blue}{\frac{n!}{(n-x)!} \bigg( \frac{1}{n} \bigg)^x} \color{red}{ \bigg( 1-\frac{\lambda}{n} \bigg)^n } \color{green}{\bigg( 1-\frac{\lambda}{n} \bigg)^{-x}}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now let’s take the limit of this right-hand side one term at a time.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We start with the blue term&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\color{blue}{ \lim_{n \to \infty} \frac{n!}{(n-x)!} \bigg( \frac{1}{n} \bigg)^x }\]&lt;/span&gt;
The numerator and denominator can be expanded as follows&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\color{blue}{ \lim_{n \to \infty} \frac{(n)(n-1)(n-2)\dots(n-x)(n-x-1)\dots (1)}{(n-x)(n-x-1)(n-x-2)\dots (1)}\bigg( \frac{1}{n} \bigg)^x }\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\((n-x)(n-x-1)\dots(1)\)&lt;/span&gt; terms cancel from both the numerator and denominator, leaving the following&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\color{blue}{ \lim_{n \to \infty} \frac{(n)(n-1)(n-2)(n-x+1)}{n^x} }\]&lt;/span&gt;
This can be rewrited as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\color{blue}{  \lim_{n \to \infty} \frac{n}{n} \frac{(n-1)}{n} \frac{(n-2)}{n} \frac{(n-x+1)}{n} }\]&lt;/span&gt;
This is because there were &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; terms in both the numerator and denominator. Clearly, every one of these &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; terms approaches 1 as &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; approaches infinity. So we know this just simplifies to one. So we’re done with the first step.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Now we focus on the red term of &lt;a href=&#34;#eq:limit&#34;&gt;(2)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\color{red}{ \lim_{n \to \infty} \bigg( 1-\frac{\lambda}{n} \bigg)^n }\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Recall the &lt;a href=&#34;https://en.wikipedia.org/wiki/E_(mathematical_constant)&#34;&gt;definition&lt;/a&gt; of &lt;span class=&#34;math inline&#34;&gt;\(e= 2.7182\dots\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \lim_{a \to \infty} \bigg(1 + \frac{1}{a}\bigg)^a\]&lt;/span&gt;
Our goal here is to find a way to manipulate our expression to look more like the definition of &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;, which we know the limit of. Let’s define a number &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ a = -\frac{n}{\lambda}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Substituting it into our expression we get&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \color{red}{ \lim_{n \to \infty} \bigg( 1-\frac{\lambda}{n} \bigg)^n = \lim_{n \to \infty} \bigg( 1+\frac{1}{a} \bigg)^{-a\lambda} = e^{-\lambda} }\]&lt;/span&gt;
So we’ve finished with the middle term.&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The third term of &lt;a href=&#34;#eq:limit&#34;&gt;(2)&lt;/a&gt; is&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\color{green}{ \lim_{n \to \infty}  \bigg( 1-\frac{\lambda}{n} \bigg)^{-x} }\]&lt;/span&gt;
As &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; approaches infinity, this term becomes &lt;span class=&#34;math inline&#34;&gt;\(1^{-x}\)&lt;/span&gt; which is equal to one. And that takes care of our last term.&lt;/p&gt;
&lt;p&gt;Putting these together we can re-write &lt;a href=&#34;#eq:limit&#34;&gt;(2)&lt;/a&gt; as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{\lambda^x}{x!}  \lim_{n \to \infty} \color{blue}{ \frac{n!}{(n-x)!} \bigg( \frac{1}{n} \bigg)^x} \color{red}{ \bigg( 1-\frac{\lambda}{n} \bigg)^n} \color{green}{ \bigg( 1-\frac{\lambda}{n} \bigg)^{-x} } = \frac{\lambda^x}{x!} \color{red}{ e^{-\lambda} }\]&lt;/span&gt;
which is the probability mass function of a Poisson random variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, i.e&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(Y = y)  = \frac{\lambda^y}{y!} e^{-\lambda}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y = 0, 1, \dots\)&lt;/span&gt;. So we have shown that the Poisson distribution is a special case of the Binomial, in which the number of trials grows to infinity and the chance of success in any trial approaches zero. And that completes the proof.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Casella and Berger (&lt;a href=&#34;#ref-casella2002statistical&#34; role=&#34;doc-biblioref&#34;&gt;2002&lt;/a&gt;)&lt;/span&gt; provide a much shorter proof based on moment generating functions.&lt;/p&gt;
&lt;p&gt;A natural question is how good is this approximation? It turns out it is quite good even for moderate &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; as we’ll see with a few numerical examples.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Code&lt;/h2&gt;
&lt;p&gt;A &lt;a href=&#34;https://www.itl.nist.gov/div898/handbook/pmc/section3/pmc331.htm&#34;&gt;rule of thumb&lt;/a&gt; says for the approximation to be good:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The sample size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; should be equal to or larger than 20 and the probability of a single success, &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;, should be smaller than or equal to 0.05. If &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; &amp;gt; 100, the approximation is excellent if &lt;span class=&#34;math inline&#34;&gt;\(np\)&lt;/span&gt; is also &amp;lt; 10.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let’s try a few scenarios. I have slightly modified the code from &lt;a href=&#34;https://www.math.utah.edu/~treiberg/M3074PoisApproxEg.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plots the pmfs of Binomial and Poisson
pl &amp;lt;- function(n, p, a, b) {
   
   clr &amp;lt;- rainbow(15)[ceiling(c(10.68978, 14.24863))]
   lambda &amp;lt;- n * p
   mx &amp;lt;- max(dbinom(a:b, n, p))
      
   plot(
      c(a:b, a:b),
      c(dbinom(a:b, n, p), dpois(a:b, lambda)),
      type = &amp;quot;n&amp;quot;,
      main = paste(&amp;quot;Poisson Approx. to Binomial, n=&amp;quot;, n, &amp;quot;, p=&amp;quot;, p, &amp;quot;, lambda=&amp;quot;, lambda),
      ylab = &amp;quot;Probability&amp;quot;,
      xlab = &amp;quot;x&amp;quot;)
   points((a:b) - .15,
          dbinom(a:b, n, p),
          type = &amp;quot;h&amp;quot;,
          col = clr[1],
          lwd = 10)
   points((a:b) + .15,
          dpois(a:b, lambda),
          type = &amp;quot;h&amp;quot;,
          col = clr[2],
          lwd = 10)
   legend(b - 3.5, mx, legend = c(&amp;quot;Binomial(x,n,p)&amp;quot;, &amp;quot;Poisson(x,lambda)&amp;quot;), fill = clr, bg = &amp;quot;white&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I start with the recommendation: &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; = 20, &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; = 0.05. This gives &lt;span class=&#34;math inline&#34;&gt;\(\lambda= 1\)&lt;/span&gt;. Already the approximation seems reasonable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pl(20, 0.05, 0, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://solon-karapanagiotis.com/post/approx_binomial/approximating-binomial-with-poisson_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; = 10, &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; = 0.3 it doesn’t seem to work very well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pl(10, 0.3, 0, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://solon-karapanagiotis.com/post/approx_binomial/approximating-binomial-with-poisson_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But if we increase &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; and decrease &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; in order to come home with the same &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; value things improve.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pl(100, 0.03, 0, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://solon-karapanagiotis.com/post/approx_binomial/approximating-binomial-with-poisson_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;
Lastly, for 1000 trials the distributions are indistinguishable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pl(1000, 0.003, 0, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://solon-karapanagiotis.com/post/approx_binomial/approximating-binomial-with-poisson_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-casella2002statistical&#34;&gt;
&lt;p&gt;Casella, George, and Roger L Berger. 2002. &lt;em&gt;Statistical Inference&lt;/em&gt;. Vol. 2. Duxbury Pacific Grove, CA.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Another solution to the &#39;The Hardest Logic Puzzle Ever&#39; using probability</title>
      <link>https://solon-karapanagiotis.com/post/hardest_puzzle/the-hardest-logic-puzzle/</link>
      <pubDate>Fri, 03 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://solon-karapanagiotis.com/post/hardest_puzzle/the-hardest-logic-puzzle/</guid>
      <description>


&lt;p&gt;I present a solution to a modification of the “hardest logic puzzle ever” using probability theory.&lt;/p&gt;
&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;“The hardest logic puzzle” was originally presented by &lt;span class=&#34;citation&#34;&gt;Boolos (&lt;a href=&#34;#ref-boolos1996hardest&#34; role=&#34;doc-biblioref&#34;&gt;1996&lt;/a&gt;)&lt;/span&gt; and since then it has been amended several times in order to make it harder &lt;span class=&#34;citation&#34;&gt;(see Rabern and Rabern &lt;a href=&#34;#ref-rabern2008simple&#34; role=&#34;doc-biblioref&#34;&gt;2008&lt;/a&gt;, @novozhilov2012hardest)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The puzzle: &lt;em&gt;Three gods A, B, and C are called, in some order, True, False, and Random. True always speaks truly, False always speaks falsely, but whether Random speaks truly or falsely is a completely random matter. Your task is to determine the identities of A, B, and C by asking three yes-no questions; &lt;strong&gt;each question must be put to exactly one god&lt;/strong&gt;. The gods understand English, but will answer all questions in their own language, in which the words for “yes” and “no” are “da” and “ja,” in some order. You do not know which word means which. &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Boolos (&lt;a href=&#34;#ref-boolos1996hardest&#34; role=&#34;doc-biblioref&#34;&gt;1996&lt;/a&gt;)&lt;/span&gt; then provides the following guidelines:&lt;br /&gt;
1. It could be that some god gets asked more than one question (and hence that some god is not asked any question at all).&lt;br /&gt;
2. What the second question is, and to which god it is put, may depend on the answer to the first question. (And of course similarly for the third question.)&lt;br /&gt;
3. Whether Random speaks truly or not should be thought of as depending on the flip of a coin hidden in his brain: if the coin comes down heads, he speaks truly; if tails, falsely.&lt;br /&gt;
4. Random will answer da or ja when asked any yes-no question.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Rabern and Rabern (&lt;a href=&#34;#ref-rabern2008simple&#34; role=&#34;doc-biblioref&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt; proposed to modify the third point above with the following:
“Whether Random answers ‘da’ or ‘ja’ should be thought of as depending on the flip of a coin hidden in his
brain: if the coin comes down heads, he answers ‘yes’; if tails, ‘no’.”&lt;/p&gt;
&lt;p&gt;Boolos’ article includes multiple ways of solving the problem. &lt;span class=&#34;citation&#34;&gt;Rabern and Rabern (&lt;a href=&#34;#ref-rabern2008simple&#34; role=&#34;doc-biblioref&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt; give a simpler solution. The main ideas for the solutions can be found &lt;a href=&#34;https://www.technologyreview.com/s/428189/the-hardest-logic-puzzle-ever-made-even-harder/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://nautil.us/issue/30/identity/how-to-solve-the-hardest-logic-puzzle-ever&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;my-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;My solution&lt;/h2&gt;
&lt;p&gt;My solution is based on the long-run frequency interpretation of probability. It involves two steps. At the first step we will identify the Random god and in step 2 we distinguish between the True and False gods.&lt;/p&gt;
&lt;p&gt;Step 1&lt;/p&gt;
&lt;p&gt;Imagine the following scenario: you keep asking the same question to each god. The question is different for each god. Under the interpretation of probability as long-run frequency both True and False will always give the same answer. For example, if A is the True god he will always answer “da” or “ja” and similarly the False god will always answer the opposite. The crucial point is that Random will change between “da” and “ja” because his answers are random, “they depend on the flip of a coin hidden in his brain”. Suppose you ask your question to Random ten times, and assuming the coin in his head is fair (i.e., P(heads) = P(tails) = 0.5) then the probability that all his answers are same ( “da” or “ja” ) is &lt;span class=&#34;math inline&#34;&gt;\(0.5^{10}\)&lt;/span&gt;, that is highly unlikely. In fact, you do not need to pre-specify how many times you ask the question, since the moment a given god switches from “da” to “ja” or vice-versa you know he is Random. Having identified Random we proceed to distinguish between True and False. An example question to each one is “are you True”?&lt;/p&gt;
&lt;p&gt;Step 2&lt;/p&gt;
&lt;p&gt;For simplicity let’s assume C is Random. Now, we only need to identify one more god. Let’s use god A for illustration. All possibilities regarding god A and the word “da” are given below:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A is True and “da” means “yes”,&lt;/li&gt;
&lt;li&gt;A is True and “da” means “no”,&lt;/li&gt;
&lt;li&gt;A is False and “da” means “yes”,&lt;/li&gt;
&lt;li&gt;A is False and “da” means “no”,&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then ask A the following question:&lt;/p&gt;
&lt;p&gt;Q1: Is C Random?&lt;/p&gt;
&lt;p&gt;And B:&lt;/p&gt;
&lt;p&gt;Q2: Is A True?&lt;/p&gt;
&lt;p&gt;For each scenario above we end up with the following pattern:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If scenario (1) the answers are “da” and “ja” for Q1 and Q2 respectively.&lt;/li&gt;
&lt;li&gt;If scenario (2) the answers are “ja” and “da”.&lt;/li&gt;
&lt;li&gt;If scenario (3) the answers are “ja” and “da”.&lt;/li&gt;
&lt;li&gt;If scenario (4) the answers are “da” and “da”.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looking more carefully at the answers we distinguish 3 distinct patterns for the answers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P1: “da”and “ja”,&lt;/li&gt;
&lt;li&gt;P2: “ja” and “da” and&lt;/li&gt;
&lt;li&gt;P3: “da” and “da”.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Furthermore, P1 and P3 are unique, they appear only once. That means if the gods answer Q1 and Q2 using P1 or P3 we have identified them and the game is over! For example, if they answer with P3 then scenario (4) was correct: A is False and “da” means “no” and consequently B is True and “ja” means “yes”. If they answer using P2 then we need a further question because both scenarios (2) and (3) may be right. We can ask A: (repeat the 1st question)&lt;/p&gt;
&lt;p&gt;Q3: Are you True?&lt;/p&gt;
&lt;p&gt;Now, if scenario (2) the answer is “ja” and if scenario (3) the answer is “da”.&lt;/p&gt;
&lt;p&gt;Using this approach we have also identified the meanings of “da” and “ja”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;comments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comments&lt;/h2&gt;
&lt;p&gt;The modification I used was allowing each question to be put to more than one god. In step 1 the question “Are you True?” was put to all gods and was repeated in step 2 as Q3. So technically I have solved the puzzle using only three questions in total, but allowing myself to repeat the same questions to more than one god.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Boolos (&lt;a href=&#34;#ref-boolos1996hardest&#34; role=&#34;doc-biblioref&#34;&gt;1996&lt;/a&gt;)&lt;/span&gt; provided his solution in the same article in which he introduced the puzzle.
He states that the “first move is to find a god that you can be certain is not Random, and hence is either True or False”. My approach does the reverse; first identifies the Random god and then the True and False gods.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-boolos1996hardest&#34;&gt;
&lt;p&gt;Boolos, George. 1996. “The Hardest Logic Puzzle Ever.” &lt;em&gt;The Harvard Review of Philosophy&lt;/em&gt; 6 (1): 62–65.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-novozhilov2012hardest&#34;&gt;
&lt;p&gt;Novozhilov, Nikolay. 2012. “The Hardest Logic Puzzle Ever Becomes Even Tougher.” &lt;em&gt;arXiv Preprint arXiv:1206.1926&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rabern2008simple&#34;&gt;
&lt;p&gt;Rabern, Brian, and Landon Rabern. 2008. “A Simple Solution to the Hardest Logic Puzzle Ever.” &lt;em&gt;Analysis&lt;/em&gt; 68 (2): 105–12.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
